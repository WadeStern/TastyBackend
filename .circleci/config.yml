version: 2.1
orbs:
  python: circleci/python@2
  kubernetes: circleci/kubernetes@1.3.1
  discord: teka23/discord@0.0.1
jobs:
  test-python:
    docker:
      - image: cimg/python:3.10
    steps:
      - checkout
      - python/install-packages
      - python/install-packages:
          args: pytest
          pkg-manager: pip
          pypi-cache: false
      - run:
          name: Run tests
          command: pytest test_main.py --junitxml=junit.xml
      - store_test_results:
          path: junit.xml
      - run:
          name: Lint Python code
          command: |
            pip install flake8
            flake8 .
          when: always

  build_docker_image:
    docker:
      - image: cimg/node:18.18.2
    steps:
      - checkout
      - setup_remote_docker:
          docker_layer_caching: false
      - run:
          name: Build Docker image
          command: |
            export TAG=0.2.<< pipeline.number >>
            export IMAGE_NAME=tastybackend           
            docker build -t $DOCKER_LOGIN/$IMAGE_NAME -t $DOCKER_LOGIN/$IMAGE_NAME:$TAG .
            echo $DOCKER_PWD | docker login -u $DOCKER_LOGIN --password-stdin
            docker push $DOCKER_LOGIN/$IMAGE_NAME
  
  create_kubernetes_cluster:
    docker:
      - image: dudesm00thie/wadeazcli
        user: root
    steps:
      - checkout
      - run:
          name: Login to Azure
          command: |
            az login --service-principal --username "${AZURE_CLIENT_ID}" --password "${AZURE_CLIENT_SECRET}" --tenant "${AZURE_TENANT_ID}"  
      - run:
          name: Configure SSH Key
          command: |
            echo "$SSH_PRIVATE_KEY" > ~/.ssh/id_rsa
            chmod 600 ~/.ssh/id_rsa
            echo "$SSH_PUBLIC_KEY" > ~/.ssh/id_rsa.pub
            chmod 600 ~/.ssh/id_rsa.pub
      - run:
          name: Delete DNS Records
          command: |
            dns_zone="staging.wadestern.com"
            records=("frontend" "backend")
            
            for record in "${records[@]}"; do
              az network dns record-set cname delete --zone-name "$dns_zone" --name "$record" --resource-group "buypotatoResourceGroup" --yes
            done
      #- run:
      #    name: Create Kubernetes Cluster
      #    command: |
      #      az aks create -g buypotatoResourceGroup -n buypotatoStaging --node-count 2 --ssh-key-value ~/.ssh/id_rsa.pub
      #      az aks get-credentials --resource-group buypotatoResourceGroup --name buypotatoStaging
      - persist_to_workspace:
          root: /root
          paths:
            - .kube/config

  setup_dns_and_deploy:
    docker:
      - image: dudesm00thie/kubeaz:latest
        user: root
    steps:
      - checkout
      - attach_workspace:
          at: /root
      - run:
          name: Login to Azure
          command: |
            az login --service-principal --username "${AZURE_CLIENT_ID}" --password "${AZURE_CLIENT_SECRET}" --tenant "${AZURE_TENANT_ID}"
      - run:
          name: Set Vars
          command: | 
            PRINCIPAL_ID=$(az aks show --resource-group buypotatoResourceGroup --name buypotatoStaging \
            --query "identityProfile.kubeletidentity.objectId" --output tsv)
            AZURE_DNS_ZONE="staging.wadestern.com" 
            AZURE_DNS_ZONE_RESOURCE_GROUP="buypotatoResourceGroup"
            DNS_ID=/subscriptions/a24f845d-8972-45b6-ab3d-9dd9e598dbeb/resourceGroups/buypotatoresourcegroup/providers/Microsoft.Network/dnszones/staging.wadestern.com
            echo $PRINCIPAL_ID
            echo $AZURE_DNS_ZONE
            echo $AZURE_DNS_ZONE_RESOURCE_GROUP
            echo $DNS_ID
            az role assignment create --role "DNS Zone Contributor" --assignee "${PRINCIPAL_ID}" --scope "${DNS_ID}"
      - run:
          name: Create kubernetes secret and namespace
          command: |
            kubectl --kubeconfig=/root/.kube/config create secret generic azure-config-file --namespace "default" --from-file /root/project/deploy/azure.json
            kubectl --kubeconfig=/root/.kube/config create --namespace "default" --filename /root/project/deploy/azure-external-dns.yaml
      - run:
          name: Deploy backend to Kubernetes
          command: kubectl --kubeconfig=/root/.kube/config apply -f /root/project/deploy/staging-backend-deploy.yaml
      - run:
          name: Deploy frontend to Kubernetes
          command: kubectl --kubeconfig=/root/.kube/config apply -f /root/project/deploy/staging-frontend-deploy.yaml
      - run:
          name: Wait for external-dns pod to be running
          command: |
            end=$((SECONDS+180))
              while [[ $SECONDS -lt $end ]]; do
                if kubectl --kubeconfig=/root/.kube/config get pods -n buypotatostaging | grep -q "0/"; then
                  sleep 10
                else
                  break
                fi
              done 
    
  puppeteer_testing:
    working_directory: ~/repo/testing
    docker:
      - image: mudbone67/node-pup-chr
    environment:
      prodorstaging: staging
    steps:
      - checkout:
          path: ~/repo
      - run:
          name: Update NPM
          command: npm install -g npm
      - restore_cache:
          key: dependency-cache-{{ checksum "package-lock.json" }}
      - run:
          name: Install Dependencies
          command: npm install
      - save_cache:
          key: dependency-cache-{{ checksum "package-lock.json" }}
          paths:
            - ./node_modules  
      - run:
          name: Wait
          command: sleep 120
      - run:
          name: List Environment Variables
          command: printenv
      - run:
          name: Run tests
          command: npm test -- --forceExit

  puppeteer_testing2:
    working_directory: ~/repo/testing
    docker:
      - image: mudbone67/node-pup-chr
    environment:
      prodorstaging: prod
    steps:
      - checkout:
          path: ~/repo
      - run:
          name: Update NPM
          command: npm install -g npm
      - restore_cache:
          key: dependency-cache-{{ checksum "package-lock.json" }}
      - run:
          name: Install Dependencies
          command: npm install
      - save_cache:
          key: dependency-cache-{{ checksum "package-lock.json" }}
          paths:
            - ./node_modules  
      - run:
          name: Wait 
          command: sleep 120
      - run:
          name: Run tests
          command: npm test -- --forceExit

  hold_notification:
    docker:
      - image: circleci/node:12
    steps:
      - discord/notify:
          message: Pending approval
          webhook: ${DISCORDWEBHOOK}
  
  Check_file_location:
    docker:
      - image: dudesm00thie/kubeeks
    steps:
      - checkout
      - run:
          name: Find files
          command: |
            pwd
            find /root

  Create_and_deploy_prod:
    docker:
      - image: dudesm00thie/kubeeks
    steps:
      - checkout
      - run:
          name: Login to AWS
          command: |
            aws configure set aws_access_key_id "${AWS_ACCESS_KEY}"
            aws configure set aws_secret_access_key "${AWS_SECRET_KEY}"
            aws configure set default.region us-east-1
            aws configure set default.output json
      - run:
          name: Setup and create cluster
          command: |
            export POLICY_ARN=$(aws iam list-policies \
            --query 'Policies[?PolicyName==`AllowExternalDNSUpdates`].Arn' --output text)
            export EKS_CLUSTER_NAME="buypotatoprod"
            export EKS_CLUSTER_REGION="us-east-1"
            export KUBECONFIG="$HOME/.kube/${EKS_CLUSTER_NAME}-${EKS_CLUSTER_REGION}.yaml"
            export AWS_PAGER=""
            #create the cluster
            eksctl create cluster --name $EKS_CLUSTER_NAME --region $EKS_CLUSTER_REGION 
            #verify OIDC is supported
            aws eks describe-cluster --name $EKS_CLUSTER_NAME \
            --query "cluster.identity.oidc.issuer" --output text
            #associate OIDC to cluster
            eksctl utils associate-iam-oidc-provider \
            --cluster $EKS_CLUSTER_NAME --region $EKS_CLUSTER_REGION --approve
            #create service account
            eksctl create iamserviceaccount \
            --region $EKS_CLUSTER_REGION \
            --cluster $EKS_CLUSTER_NAME \
            --name "external-dns" \
            --namespace ${EXTERNALDNS_NS:-"default"} \
            --attach-policy-arn $POLICY_ARN \
            --approve
            #Kubectl statements
            #kubectl create namespace default
            kubectl create --filename deploy/externaldns-with-rbac.yaml \
            --namespace default
            #Apply frontend/backend
            kubectl apply -f deploy/prod-backend-deploy.yaml
            kubectl apply -f deploy/production-frontend-deploy.yaml

  AWS_Cleanup:
    docker:
      - image: dudesm00thie/kubeeks 
    steps:
      - checkout
      - attach_workspace:
          at: /root
      - run:
          name: Login to AWS
          command: |
            aws configure set aws_access_key_id "${AWS_ACCESS_KEY}"
            aws configure set aws_secret_access_key "${AWS_SECRET_KEY}"
            aws configure set default.region us-east-1
            aws configure set default.output json
      - run:
          name: cleanup AWS
          command: |
            export POLICY_ARN=$(aws iam list-policies \
            --query 'Policies[?PolicyName==`AllowExternalDNSUpdates`].Arn' --output text)
            export EKS_CLUSTER_NAME="buypotatoprod"
            export EKS_CLUSTER_REGION="us-east-1"
            export KUBECONFIG="$HOME/.kube/${EKS_CLUSTER_NAME}-${EKS_CLUSTER_REGION}.yaml"
            export AWS_PAGER=""
            eksctl delete cluster --name $EKS_CLUSTER_NAME --region $EKS_CLUSTER_REGION
            aws cloudformation delete-stack --stack-name eksctl-buypotatoprod-cluster
            export AWS_PAGER=""

  Azure_Cleanup:
    docker:
      - image: dudesm00thie/kubeaz:latest
        user: root
    steps:
      - checkout
      - attach_workspace:
          at: /root
      - run:
          name: Login to Azure
          command: |
            az login --service-principal --username "${AZURE_CLIENT_ID}" --password "${AZURE_CLIENT_SECRET}" --tenant "${AZURE_TENANT_ID}"
      - run:
          name: Delete Kubernetes Cluster
          command: |
            az aks delete --resource-group buypotatoResourceGroup --name buypotatoStaging --yes


workflows:
  build-and-test:
    jobs:
      - test-python
      - build_docker_image:
          requires:
            - test-python
      - create_kubernetes_cluster:
          requires:
            - build_docker_image
#      - setup_dns_and_deploy:
#          requires:
#            - create_kubernetes_cluster
#      - puppeteer_testing :
#          requires:
#            - setup_dns_and_deploy
#      - hold_notification:
#          requires:
#            - puppeteer_testing
#      - hold_puppeteer:
#          type: approval
#          requires:
#            - puppeteer_testing
#      - Create_and_deploy_prod:
#          requires:
#            - hold_puppeteer
#      - puppeteer_testing2:
#          requires:
#            - Create_and_deploy_prod
#      - Azure_Cleanup:
#          requires:
#            - puppeteer_testing2
#      - hold_cleanup:
#          type: approval
#          requires:
#            - puppeteer_testing2
#      - hold_notification:
#          requires:
#            - puppeteer_testing2
#      - AWS_Cleanup:
#          requires: 
#            - hold_cleanup

